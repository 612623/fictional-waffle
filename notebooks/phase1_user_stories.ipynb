{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 1 - Lab 1: AI-Powered Requirements & User Stories\n",
    "\n",
    "**Objective:** Use a Large Language Model (LLM) to decompose a vague problem statement into structured features, user personas, and Agile user stories, culminating in a machine-readable JSON artifact.\n",
    "\n",
    "**Estimated Time:** 90 minutes\n",
    "\n",
    "**Introduction:**\n",
    "Welcome to the first hands-on lab of the AI-Driven Software Engineering Program! All great software projects begin with a clear understanding of the problem to be solved. In this lab, you will take on the role of a tech lead or product manager and use an LLM as a co-pilot to transform a simple, high-level problem into a set of well-defined, actionable requirements. This process is fundamental to ensuring that the team builds the *right* product.\n",
    "\n",
    "For definitions of key terms used in this lab, please refer to the [GLOSSARY.md](../../GLOSSARY.md)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Setup\n",
    "\n",
    "This initial block sets up our environment. It adds the project's root directory to the Python path, allowing us to import our custom `utils.py` script. We then initialize the connection to our Large Language Model (LLM).\n",
    "\n",
    "**Model Selection:**\n",
    "Our `utils.py` script is configured to work with multiple AI providers. You can change the `model_name` parameter in the `setup_llm_client()` function to any of the models listed in the `RECOMMENDED_MODELS` dictionary in `utils.py`. For example, to use a Hugging Face model, you could change the line to: `client, model_name, api_provider = setup_llm_client(model_name=\"meta-llama/Llama-3.3-70B-Instruct\")`\n",
    "\n",
    "**Helper Functions Used:**\n",
    "- `setup_llm_client()`: To configure the API client for our chosen LLM.\n",
    "- `get_completion()`: To send a prompt to the LLM and get a response.\n",
    "- `save_artifact()`: To save our generated requirements to a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-22 15:32:00,031 ag_aisoftdev.utils INFO LLM Client configured provider=openai model=o3 latency_ms=None artifacts_path=None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<persona>\n",
      "You are a Senior Product Manager and Certified Agile Coach with extensive experience in requirements elicitation and JSON data modeling.\n",
      "</persona>\n",
      "\n",
      "<context>\n",
      "Goal: Generate the full contents of a JSON file named “ex3.json”.  \n",
      "Scope: The file must illustrate three key categories—product features, user personas, and agile user stories—so that a development team can immediately import it into their tooling.  \n",
      "Definitions  \n",
      "• Feature: A discrete, end-user–visible capability that delivers business value (e.g., “Dark Mode”).  \n",
      "• User Persona: A fictional archetype representing a user segment, containing a name, role, goals, frustrations, and demographic summary.  \n",
      "• Agile User Story: A requirement expressed in the format “As a [persona], I want [capability] so that [benefit].”  \n",
      "Constraints  \n",
      "• Valid JSON only, UTF-8, no comments or trailing commas.  \n",
      "• Root object keys: \"features\", \"personas\", \"userStories\".  \n",
      "• Provide 5 items per category (15 objects total).  \n",
      "• Each feature object: { \"id\": string, \"name\": string, \"description\": string, \"priority\": \"Low|Medium|High\" }.  \n",
      "• Each persona object: { \"id\": string, \"name\": string, \"role\": string, \"goals\": [string], \"frustrations\": [string], \"demographics\": { \"ageRange\": string, \"location\": string } }.  \n",
      "• Each userStory object: { \"id\": string, \"story\": string, \"acceptanceCriteria\": [string], \"businessValue\": integer, \"storyPoints\": integer }.  \n",
      "• IDs must be unique across the entire file.  \n",
      "• Sort all arrays alphabetically by id.\n",
      "</context>\n",
      "\n",
      "<instructions>\n",
      "1. Think step by step to decide appropriate, realistic content for each category.  \n",
      "2. Verify all constraints are met, especially JSON validity and unique IDs.  \n",
      "3. Output ONLY the final JSON—no explanations, headers, or surrounding text.\n",
      "</instructions>\n",
      "\n",
      "<examples>\n",
      "Example (truncated for illustration only; do NOT reuse values):\n",
      "\n",
      "{\n",
      "  \"features\": [\n",
      "    { \"id\": \"F001\", \"name\": \"Dark Mode\", \"description\": \"Low-light interface...\", \"priority\": \"High\" }\n",
      "  ],\n",
      "  \"personas\": [\n",
      "    { \"id\": \"P001\", \"name\": \"Alex Analyst\", \"role\": \"Data Analyst\", \"goals\": [\"Quick insights\"], \"frustrations\": [\"Slow exports\"], \"demographics\": { \"ageRange\": \"25-34\", \"location\": \"USA\" } }\n",
      "  ],\n",
      "  \"userStories\": [\n",
      "    { \"id\": \"US001\", \"story\": \"As Alex Analyst, I want to export data in CSV so that I can analyze it offline.\", \"acceptanceCriteria\": [\"Export button visible\", \"File downloads\"], \"businessValue\": 800, \"storyPoints\": 5 }\n",
      "  ]\n",
      "}\n",
      "</examples>\n",
      "\n",
      "<output_format>\n",
      "Return the complete JSON object that satisfies all constraints above.\n",
      "</output_format>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-22 15:32:19,120 ag_aisoftdev.utils INFO LLM Client configured provider=anthropic model=claude-sonnet-4-20250514 latency_ms=None artifacts_path=None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "WindowsPath('C:/Users/labadmin/AG-AISOFTDEV/artifacts/ex3.json')"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Add the project's root directory to the Python path to ensure 'utils' can be imported.\n",
    "try:\n",
    "    # Assumes the notebook is in 'labs/Day_01_.../'\n",
    "    project_root = os.path.abspath(os.path.join(os.getcwd(), '..', '..'))\n",
    "except IndexError:\n",
    "    # Fallback for different execution environments\n",
    "    project_root = os.path.abspath(os.path.join(os.getcwd()))\n",
    "\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "from utils import setup_llm_client, get_completion, save_artifact, recommended_models_table, prompt_enhancer\n",
    "\n",
    "prompt = \"create a json file named ex3.json that contains examples of features, user personas, and agile user stories\"\n",
    "prompt = prompt_enhancer(prompt)\n",
    "print(prompt)\n",
    "\n",
    "# Initialize the LLM client. You can change the model here.\n",
    "# For example: setup_llm_client(model_name=\"gemini-2.5-flash\")\n",
    "#client, model_name, api_provider = setup_llm_client(model_name=\"gpt-4o\")\n",
    "client, model_name, api_provider = setup_llm_client(model_name=\"claude-sonnet-4-20250514\")\n",
    "\n",
    "output = get_completion(prompt, client=client, model_name=model_name, api_provider=api_provider)\n",
    "\n",
    "save_artifact(output, \"ex3.json\", overwrite=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "| Model | Provider | Text | Vision | Image Gen | Image Edit | Audio Transcription | Context Window | Max Output Tokens |\n",
       "|---|---|---|---|---|---|---|---|---|\n",
       "| Qwen/Qwen-Image | huggingface | ❌ | ❌ | ✅ | ❌ | ❌ | - | - |\n",
       "| Qwen/Qwen-Image-Edit | huggingface | ❌ | ❌ | ❌ | ✅ | ❌ | - | - |\n",
       "| black-forest-labs/FLUX.1-Kontext-dev | huggingface | ❌ | ❌ | ❌ | ✅ | ❌ | - | - |\n",
       "| claude-opus-4-1-20250805 | anthropic | ✅ | ✅ | ❌ | ❌ | ❌ | 200,000 | 100,000 |\n",
       "| claude-opus-4-20250514 | anthropic | ✅ | ✅ | ❌ | ❌ | ❌ | 200,000 | 100,000 |\n",
       "| claude-sonnet-4-20250514 | anthropic | ✅ | ✅ | ❌ | ❌ | ❌ | 1,000,000 | 100,000 |\n",
       "| dall-e-3 | openai | ❌ | ❌ | ✅ | ❌ | ❌ | - | - |\n",
       "| deepseek-ai/DeepSeek-V3.1 | huggingface | ✅ | ❌ | ❌ | ❌ | ❌ | 128,000 | 100,000 |\n",
       "| gemini-1.5-flash | google | ✅ | ✅ | ❌ | ❌ | ❌ | 1,000,000 | 8,192 |\n",
       "| gemini-1.5-pro | google | ✅ | ✅ | ❌ | ❌ | ❌ | 2,000,000 | 8,192 |\n",
       "| gemini-2.0-flash-exp | google | ✅ | ✅ | ❌ | ❌ | ❌ | 1,048,576 | 8,192 |\n",
       "| gemini-2.0-flash-preview-image-generation | google | ❌ | ❌ | ✅ | ❌ | ❌ | 32,000 | 8,192 |\n",
       "| gemini-2.5-flash | google | ✅ | ✅ | ❌ | ❌ | ❌ | 1,048,576 | 65,536 |\n",
       "| gemini-2.5-flash-image-preview | google | ❌ | ❌ | ✅ | ❌ | ❌ | 32,768 | 32,768 |\n",
       "| gemini-2.5-flash-lite | google | ✅ | ✅ | ❌ | ❌ | ❌ | 1,048,576 | 65,536 |\n",
       "| gemini-2.5-pro | google | ✅ | ✅ | ❌ | ❌ | ❌ | 1,048,576 | 65,536 |\n",
       "| gemini-live-2.5-flash-preview | google | ❌ | ❌ | ❌ | ❌ | ❌ | 1,048,576 | 8,192 |\n",
       "| gpt-4.1 | openai | ✅ | ✅ | ❌ | ❌ | ❌ | 1,000,000 | 32,768 |\n",
       "| gpt-4.1-mini | openai | ✅ | ✅ | ❌ | ❌ | ❌ | 1,000,000 | 32,000 |\n",
       "| gpt-4.1-nano | openai | ✅ | ✅ | ❌ | ❌ | ❌ | 1,000,000 | 32,000 |\n",
       "| gpt-4o | openai | ✅ | ✅ | ❌ | ❌ | ❌ | 128,000 | 16,384 |\n",
       "| gpt-4o-mini | openai | ✅ | ✅ | ❌ | ❌ | ❌ | 128,000 | 16,384 |\n",
       "| gpt-5-2025-08-07 | openai | ✅ | ✅ | ❌ | ❌ | ❌ | 400,000 | 128,000 |\n",
       "| gpt-5-mini-2025-08-07 | openai | ✅ | ✅ | ❌ | ❌ | ❌ | 400,000 | 128,000 |\n",
       "| gpt-5-nano-2025-08-07 | openai | ✅ | ✅ | ❌ | ❌ | ❌ | 400,000 | 128,000 |\n",
       "| meta-llama/Llama-3.3-70B-Instruct | huggingface | ✅ | ❌ | ❌ | ❌ | ❌ | 8,192 | 4,096 |\n",
       "| meta-llama/Llama-4-Maverick-17B-128E-Instruct | huggingface | ✅ | ❌ | ❌ | ❌ | ❌ | 1,000,000 | 100,000 |\n",
       "| meta-llama/Llama-4-Scout-17B-16E-Instruct | huggingface | ✅ | ❌ | ❌ | ❌ | ❌ | 10,000,000 | 100,000 |\n",
       "| mistralai/Mistral-7B-Instruct-v0.3 | huggingface | ✅ | ❌ | ❌ | ❌ | ❌ | 32,768 | 8,192 |\n",
       "| o3 | openai | ✅ | ✅ | ❌ | ❌ | ❌ | 200,000 | 100,000 |\n",
       "| o4-mini | openai | ✅ | ✅ | ❌ | ❌ | ❌ | 200,000 | 100,000 |\n",
       "| stabilityai/stable-diffusion-3.5-large | huggingface | ❌ | ❌ | ✅ | ❌ | ❌ | - | - |\n",
       "| tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.5 | huggingface | ✅ | ❌ | ❌ | ❌ | ❌ | 4,096 | 1,024 |\n",
       "| veo-3.0-fast-generate-preview | google | ❌ | ❌ | ❌ | ❌ | ❌ | 1,024 | - |\n",
       "| veo-3.0-generate-preview | google | ❌ | ❌ | ❌ | ❌ | ❌ | 1,024 | - |\n",
       "| whisper-1 | openai | ❌ | ❌ | ❌ | ❌ | ✅ | - | - |"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'| Model | Provider | Text | Vision | Image Gen | Image Edit | Audio Transcription | Context Window | Max Output Tokens |\\n|---|---|---|---|---|---|---|---|---|\\n| Qwen/Qwen-Image | huggingface | ❌ | ❌ | ✅ | ❌ | ❌ | - | - |\\n| Qwen/Qwen-Image-Edit | huggingface | ❌ | ❌ | ❌ | ✅ | ❌ | - | - |\\n| black-forest-labs/FLUX.1-Kontext-dev | huggingface | ❌ | ❌ | ❌ | ✅ | ❌ | - | - |\\n| claude-opus-4-1-20250805 | anthropic | ✅ | ✅ | ❌ | ❌ | ❌ | 200,000 | 100,000 |\\n| claude-opus-4-20250514 | anthropic | ✅ | ✅ | ❌ | ❌ | ❌ | 200,000 | 100,000 |\\n| claude-sonnet-4-20250514 | anthropic | ✅ | ✅ | ❌ | ❌ | ❌ | 1,000,000 | 100,000 |\\n| dall-e-3 | openai | ❌ | ❌ | ✅ | ❌ | ❌ | - | - |\\n| deepseek-ai/DeepSeek-V3.1 | huggingface | ✅ | ❌ | ❌ | ❌ | ❌ | 128,000 | 100,000 |\\n| gemini-1.5-flash | google | ✅ | ✅ | ❌ | ❌ | ❌ | 1,000,000 | 8,192 |\\n| gemini-1.5-pro | google | ✅ | ✅ | ❌ | ❌ | ❌ | 2,000,000 | 8,192 |\\n| gemini-2.0-flash-exp | google | ✅ | ✅ | ❌ | ❌ | ❌ | 1,048,576 | 8,192 |\\n| gemini-2.0-flash-preview-image-generation | google | ❌ | ❌ | ✅ | ❌ | ❌ | 32,000 | 8,192 |\\n| gemini-2.5-flash | google | ✅ | ✅ | ❌ | ❌ | ❌ | 1,048,576 | 65,536 |\\n| gemini-2.5-flash-image-preview | google | ❌ | ❌ | ✅ | ❌ | ❌ | 32,768 | 32,768 |\\n| gemini-2.5-flash-lite | google | ✅ | ✅ | ❌ | ❌ | ❌ | 1,048,576 | 65,536 |\\n| gemini-2.5-pro | google | ✅ | ✅ | ❌ | ❌ | ❌ | 1,048,576 | 65,536 |\\n| gemini-live-2.5-flash-preview | google | ❌ | ❌ | ❌ | ❌ | ❌ | 1,048,576 | 8,192 |\\n| gpt-4.1 | openai | ✅ | ✅ | ❌ | ❌ | ❌ | 1,000,000 | 32,768 |\\n| gpt-4.1-mini | openai | ✅ | ✅ | ❌ | ❌ | ❌ | 1,000,000 | 32,000 |\\n| gpt-4.1-nano | openai | ✅ | ✅ | ❌ | ❌ | ❌ | 1,000,000 | 32,000 |\\n| gpt-4o | openai | ✅ | ✅ | ❌ | ❌ | ❌ | 128,000 | 16,384 |\\n| gpt-4o-mini | openai | ✅ | ✅ | ❌ | ❌ | ❌ | 128,000 | 16,384 |\\n| gpt-5-2025-08-07 | openai | ✅ | ✅ | ❌ | ❌ | ❌ | 400,000 | 128,000 |\\n| gpt-5-mini-2025-08-07 | openai | ✅ | ✅ | ❌ | ❌ | ❌ | 400,000 | 128,000 |\\n| gpt-5-nano-2025-08-07 | openai | ✅ | ✅ | ❌ | ❌ | ❌ | 400,000 | 128,000 |\\n| meta-llama/Llama-3.3-70B-Instruct | huggingface | ✅ | ❌ | ❌ | ❌ | ❌ | 8,192 | 4,096 |\\n| meta-llama/Llama-4-Maverick-17B-128E-Instruct | huggingface | ✅ | ❌ | ❌ | ❌ | ❌ | 1,000,000 | 100,000 |\\n| meta-llama/Llama-4-Scout-17B-16E-Instruct | huggingface | ✅ | ❌ | ❌ | ❌ | ❌ | 10,000,000 | 100,000 |\\n| mistralai/Mistral-7B-Instruct-v0.3 | huggingface | ✅ | ❌ | ❌ | ❌ | ❌ | 32,768 | 8,192 |\\n| o3 | openai | ✅ | ✅ | ❌ | ❌ | ❌ | 200,000 | 100,000 |\\n| o4-mini | openai | ✅ | ✅ | ❌ | ❌ | ❌ | 200,000 | 100,000 |\\n| stabilityai/stable-diffusion-3.5-large | huggingface | ❌ | ❌ | ✅ | ❌ | ❌ | - | - |\\n| tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.5 | huggingface | ✅ | ❌ | ❌ | ❌ | ❌ | 4,096 | 1,024 |\\n| veo-3.0-fast-generate-preview | google | ❌ | ❌ | ❌ | ❌ | ❌ | 1,024 | - |\\n| veo-3.0-generate-preview | google | ❌ | ❌ | ❌ | ❌ | ❌ | 1,024 | - |\\n| whisper-1 | openai | ❌ | ❌ | ❌ | ❌ | ✅ | - | - |'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommended_models_table()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: The Problem Statement\n",
    "\n",
    "Every project starts with a problem. Our problem is a common one in many organizations:\n",
    "\n",
    "> **\"We need a tool to help our company's new hires get up to speed.\"**\n",
    "\n",
    "This statement is intentionally vague. Our job is to use the LLM to add structure and detail to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem_statement = \"We need a tool to help our company's new hires get up to speed.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: The Challenges\n",
    "\n",
    "Complete the following challenges in order. Each one builds upon the last, increasing in technical complexity and value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 1 (Foundational): Brainstorming Features\n",
    "\n",
    "**Task:** Use the LLM to brainstorm a list of potential features and user personas based on the problem statement.\n",
    "\n",
    "**Instructions:**\n",
    "1. Write a simple prompt that asks the LLM to brainstorm features for the onboarding tool.\n",
    "2. Write a second prompt to identify three distinct user personas who would use this tool.\n",
    "3. Run both prompts and review the markdown output.\n",
    "\n",
    "**Expected Quality:** The output should be a simple, readable markdown list of features and a description of the personas. This is a good first step but lacks the structure needed for automation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Brainstorming Features ---\n",
      "Here's a comprehensive brainstorm of features for a new hire onboarding tool:\n",
      "\n",
      "## **Core Task Management**\n",
      "- **Interactive checklist** with progress tracking and completion percentages\n",
      "- **Smart task prioritization** based on deadlines, dependencies, and role requirements\n",
      "- **Automated reminders** via email, SMS, or in-app notifications\n",
      "- **Task dependencies mapping** (e.g., can't access systems until IT setup complete)\n",
      "- **Bulk task completion** for similar items\n",
      "- **Custom task templates** by department/role\n",
      "\n",
      "## **Guidance & Navigation**\n",
      "- **Step-by-step walkthroughs** with screenshots and videos\n",
      "- **Interactive tutorials** for company systems and tools\n",
      "- **Virtual assistant/chatbot** for instant Q&A\n",
      "- **Smart suggestions** for next best actions\n",
      "- **Contextual help tooltips** throughout the interface\n",
      "- **Mobile-friendly design** for on-the-go completion\n",
      "\n",
      "## **Integration & Automation**\n",
      "- **Single sign-on (SSO)** integration with company systems\n",
      "- **Auto-population** of forms using existing HR data\n",
      "- **Calendar integration** for scheduling meetings and trainings\n",
      "- **Document management** with e-signature capabilities\n",
      "- **API connections** to HR systems, IT provisioning, and payroll\n",
      "- **Slack/Teams integration** for notifications and updates\n",
      "\n",
      "## **Social & Support Features**\n",
      "- **Buddy/mentor matching** system\n",
      "- **New hire cohort groups** for peer connections\n",
      "- **Manager dashboard** for tracking direct report progress\n",
      "- **Escalation workflows** when tasks are overdue\n",
      "- **Live chat support** with HR or IT teams\n",
      "- **Feedback collection** on the onboarding experience\n",
      "\n",
      "## **Personalization & Intelligence**\n",
      "- **Role-based task customization**\n",
      "- **Location-specific requirements** (different offices/countries)\n",
      "- **Learning path recommendations** based on role and career goals\n",
      "- **Adaptive timelines** that adjust based on progress\n",
      "- **Personalized welcome messages** and company culture content\n",
      "- **Skills assessment integration** to tailor training needs\n",
      "\n",
      "## **Analytics & Reporting**\n",
      "- **Progress dashboards** for individuals and managers\n",
      "- **Completion rate analytics** across departments\n",
      "- **Bottleneck identification** for process improvement\n",
      "- **Time-to-productivity metrics**\n",
      "- **Satisfaction surveys** and sentiment tracking\n",
      "- **Compliance reporting** for regulatory requirements\n",
      "\n",
      "## **Content & Resources**\n",
      "- **Centralized document library** with version control\n",
      "- **Interactive org chart** with team introductions\n",
      "- **Company culture videos** and virtual office tours\n",
      "- **Policy acknowledgment tracking**\n",
      "- **Resource recommendations** based on role and interests\n",
      "- **FAQ database** with search functionality\n",
      "\n",
      "Would you like me to elaborate on any of these feature categories or explore specific use cases?\n",
      "\n",
      "--- Identifying User Personas ---\n",
      "# User Personas for New Hire Onboarding Tool\n",
      "\n",
      "## Persona 1: Sarah Chen - The Eager Graduate\n",
      "**Demographics:**\n",
      "- Age: 24\n",
      "- Role: Junior Software Developer\n",
      "- Background: Recent computer science graduate, first full-time corporate job\n",
      "- Tech comfort level: High\n",
      "\n",
      "**Goals & Motivations:**\n",
      "- Make a great first impression and prove her capabilities\n",
      "- Understand company culture and processes quickly\n",
      "- Connect with teammates and build relationships\n",
      "- Start contributing to projects as soon as possible\n",
      "\n",
      "**Pain Points:**\n",
      "- Overwhelmed by the volume of information and tasks\n",
      "- Unclear about task priorities and deadlines\n",
      "- Anxious about missing important steps\n",
      "- Doesn't know who to ask for help without seeming incompetent\n",
      "\n",
      "**Behaviors:**\n",
      "- Checks emails and systems frequently\n",
      "- Takes detailed notes during meetings\n",
      "- Researches company information online\n",
      "- Stays late to catch up on tasks\n",
      "\n",
      "**Tool Needs:**\n",
      "- Clear task prioritization and progress tracking\n",
      "- Easy access to company resources and documentation\n",
      "- Built-in help or FAQ system\n",
      "- Integration with existing company tools\n",
      "\n",
      "---\n",
      "\n",
      "## Persona 2: Marcus Rodriguez - The Career Switcher\n",
      "**Demographics:**\n",
      "- Age: 35\n",
      "- Role: Marketing Manager\n",
      "- Background: Former teacher transitioning to corporate marketing, has management experience but new to this industry\n",
      "- Tech comfort level: Medium\n",
      "\n",
      "**Goals & Motivations:**\n",
      "- Successfully transition career paths\n",
      "- Leverage transferable skills while learning new industry practices\n",
      "- Establish credibility with new team\n",
      "- Balance onboarding with immediate job responsibilities\n",
      "\n",
      "**Pain Points:**\n",
      "- Juggling onboarding tasks with actual work assignments\n",
      "- Learning industry-specific tools and processes\n",
      "- Feeling behind compared to others with similar titles\n",
      "- Time management between training and deliverables\n",
      "\n",
      "**Behaviors:**\n",
      "- Prefers structured learning with clear timelines\n",
      "- Asks clarifying questions to ensure understanding\n",
      "- Compares new processes to previous experience\n",
      "- Seeks mentorship and guidance\n",
      "\n",
      "**Tool Needs:**\n",
      "- Flexible scheduling to accommodate work demands\n",
      "- Progress saving and resume functionality\n",
      "- Role-specific content filtering\n",
      "- Reminder and deadline management features\n",
      "\n",
      "---\n",
      "\n",
      "## Persona 3: Jennifer Kim - The Remote Executive\n",
      "**Demographics:**\n",
      "- Age: 42\n",
      "- Role: Director of Operations\n",
      "- Background: Senior executive hired from competitor, working remotely\n",
      "- Tech comfort level: Medium-High\n",
      "\n",
      "**Goals & Motivations:**\n",
      "- Quickly understand organizational structure and key stakeholders\n",
      "- Learn company-specific processes and systems\n",
      "- Build relationships with direct reports and peers remotely\n",
      "- Make strategic decisions informed by company context\n",
      "\n",
      "**Pain Points:**\n",
      "- Limited face-to-face interaction for relationship building\n",
      "- Difficulty getting quick answers to urgent questions\n",
      "- Balancing onboarding with immediate leadership responsibilities\n",
      "- Understanding informal company culture and communication norms\n",
      "\n",
      "**Behaviors:**\n",
      "- Schedules one-on-one meetings with key stakeholders\n",
      "- Reviews company materials during off-hours\n",
      "- Seeks executive summary versions of information\n",
      "- Delegates when possible to focus on strategic priorities\n",
      "\n",
      "**Tool Needs:**\n",
      "- Executive-level content with strategic focus\n",
      "- Integration with calendar and communication tools\n",
      "- Stakeholder contact directory with context\n",
      "- Mobile accessibility for flexible completion\n",
      "- Escalation paths for urgent questions\n"
     ]
    }
   ],
   "source": [
    "# TODO: Create a string variable named 'features_prompt'.\n",
    "# This prompt should ask the LLM to brainstorm features based on the problem_statement.\n",
    "features_prompt = \"Brainstorm features for the following problem statement: a tool that helps new hires quickly finish onboarding tasks\"\n",
    "\n",
    "print(\"--- Brainstorming Features ---\")\n",
    "brainstormed_features = get_completion(features_prompt, client, model_name, api_provider)\n",
    "print(brainstormed_features)\n",
    "\n",
    "# TODO: Create a string variable named 'personas_prompt'.\n",
    "# This prompt should ask the LLM to identify three user personas based on the problem_statement.\n",
    "personas_prompt = \"Create 3 example user personas for the problem statement: a tool that helps new hires quickly finish onboarding tasks\"\n",
    "\n",
    "print(\"\\n--- Identifying User Personas ---\")\n",
    "user_personas = get_completion(personas_prompt, client, model_name, api_provider)\n",
    "print(user_personas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 2 (Intermediate): Generating Formal User Stories\n",
    "\n",
    "**Task:** Now, let's increase the value by generating structured, formal Agile User Stories.\n",
    "\n",
    "**Instructions:**\n",
    "1. Create a new, more sophisticated prompt.\n",
    "2. This prompt should instruct the LLM to act as a Senior Product Manager.\n",
    "3. It must use the brainstormed features and personas from the previous step as context.\n",
    "4. The key instruction is to generate a list of user stories, each with detailed acceptance criteria in Gherkin format (`Given/When/Then`).\n",
    "5. **Crucially, the prompt must demand the final output be a well-formed JSON array of objects.** Each object should represent a user story and have keys like `id`, `user_story`, `persona`, and `acceptance_criteria`.\n",
    "\n",
    "> **Tip:** If the LLM's output isn't perfect JSON, try making your prompt even more specific. You can tell it, 'Do not include any text before or after the JSON array. Your response must begin with [ and end with ].'\n",
    "\n",
    "**Expected Quality:** The output should not be markdown, but a clean, parsable JSON string. This is a significant step up in value, as a JSON artifact can be automatically processed by other systems (e.g., imported into Jira)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Generating User Stories as JSON ---\n",
      "Successfully parsed LLM output as JSON.\n",
      "\n",
      "--- Sample User Story ---\n",
      "{\n",
      "  \"id\": 1,\n",
      "  \"feature\": \"Interactive checklist with progress tracking\",\n",
      "  \"persona\": \"Sarah Chen - The Eager Graduate\",\n",
      "  \"user_story\": \"As an eager new graduate, I want an interactive checklist with progress tracking so that I can see exactly what I've completed and what's left to do, reducing my anxiety about missing important steps.\",\n",
      "  \"acceptance_criteria\": [\n",
      "    \"Checklist displays all onboarding tasks with clear completion status\",\n",
      "    \"Progress bar shows percentage of tasks completed\",\n",
      "    \"Completed tasks are visually distinguished from pending ones\",\n",
      "    \"User can check off tasks as completed\",\n",
      "    \"Progress persists across sessions\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# TODO: Create a detailed prompt string named 'json_user_stories_prompt'.\n",
    "# This prompt needs to instruct the LLM to act as a Senior Product Manager and convert the\n",
    "# brainstormed features and personas into a structured JSON array of user stories.\n",
    "# Tip: Be very specific about the required JSON format in your prompt instructions. Tell it what keys to use and what the data types should be.\n",
    "json_user_stories_prompt = f\"Act as a Senior Product Manager. Based on the following problem \\\n",
    "                            statement: '{problem_statement}', use the brainstormed features: \\\n",
    "                            '{brainstormed_features}' and user personas: '{user_personas}' to \\\n",
    "                            create a JSON array of user stories. Each user story should be an \\\n",
    "                            object with the following keys: 'id' (int), 'feature' (string), 'persona' (string), \\\n",
    "                            'user_story' (string in the format 'As a [persona], I want [feature] \\\n",
    "                            so that [benefit]'), and 'acceptance_criteria' (array of strings). \\\n",
    "                            Ensure the JSON is properly formatted.\"\n",
    "\n",
    "print(\"--- Generating User Stories as JSON ---\")\n",
    "json_output_str = get_completion(json_user_stories_prompt, client, model_name, api_provider, temperature=0.2)\n",
    "\n",
    "# Let's try to parse the JSON to see if the LLM followed instructions\n",
    "try:\n",
    "    # The LLM might wrap the JSON in markdown fences (```json ... ```).\n",
    "    # We'll clean that up before parsing.\n",
    "    if '```' in json_output_str:\n",
    "        json_output_str = json_output_str.split('```')[1].lstrip('json').strip()\n",
    "    \n",
    "    user_stories_json = json.loads(json_output_str)\n",
    "    print(\"Successfully parsed LLM output as JSON.\")\n",
    "    \n",
    "    if user_stories_json:\n",
    "        print(\"\\n--- Sample User Story ---\")\n",
    "        print(json.dumps(user_stories_json[0], indent=2))\n",
    "    else:\n",
    "        print(\"JSON array is empty.\")\n",
    "\n",
    "except (json.JSONDecodeError, TypeError, IndexError) as e:\n",
    "    print(f\"Error: Failed to parse LLM output as JSON. Error: {e}\")\n",
    "    print(\"LLM Output was:\\n\", json_output_str)\n",
    "    user_stories_json = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 3 (Advanced): Programmatic Validation and Artifact Creation\n",
    "\n",
    "**Task:** Now for the highest-value step. Instead of just looking at the JSON, we will programmatically validate it and save it as a formal project artifact. This ensures reliability and prepares the requirements for automated use in later stages of the SDLC.\n",
    "\n",
    "**Instructions:**\n",
    "1. Complete the `validate_and_save_stories` function below.\n",
    "2. The function should iterate through the list of stories.\n",
    "3. For each story, it must validate that the required keys are present and that the acceptance criteria list is not empty.\n",
    "4. If all stories are valid, it should save the data to `artifacts/day1_user_stories.json`.\n",
    "\n",
    "**Expected Quality:** A robust script that guarantees the integrity of our requirements artifact. The final output is a validated `day1_user_stories.json` file in the `artifacts` directory, ready to be used as a reliable input for Day 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All user stories passed validation.\n"
     ]
    },
    {
     "ename": "ArtifactError",
     "evalue": "Artifact already exists: C:\\Users\\labadmin\\AG-AISOFTDEV\\artifacts\\day1_user_stories.json. Pass overwrite=True to replace.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mArtifactError\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[70]\u001b[39m\u001b[32m, line 47\u001b[39m\n\u001b[32m     45\u001b[39m \u001b[38;5;66;03m# Run the validation on the JSON data from the previous step\u001b[39;00m\n\u001b[32m     46\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33muser_stories_json\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mlocals\u001b[39m() \u001b[38;5;129;01mand\u001b[39;00m user_stories_json:\n\u001b[32m---> \u001b[39m\u001b[32m47\u001b[39m     \u001b[43mvalidate_and_save_stories\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_stories_json\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     48\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     49\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mSkipping validation as user_stories_json is empty or not defined.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[70]\u001b[39m\u001b[32m, line 40\u001b[39m, in \u001b[36mvalidate_and_save_stories\u001b[39m\u001b[34m(stories_data)\u001b[39m\n\u001b[32m     36\u001b[39m     artifact_path = \u001b[33m\"\u001b[39m\u001b[33martifacts/day1_user_stories.json\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     38\u001b[39m     \u001b[38;5;66;03m# TODO: Call the save_artifact function from utils.py to save the data.\u001b[39;00m\n\u001b[32m     39\u001b[39m     \u001b[38;5;66;03m# Remember to convert the Python list back to a JSON string using json.dumps().\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m     \u001b[43msave_artifact\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdumps\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstories_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindent\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43martifact_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     41\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUser stories saved to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00martifact_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     42\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\labadmin\\AG-AISOFTDEV\\utils\\artifacts.py:162\u001b[39m, in \u001b[36msave_artifact\u001b[39m\u001b[34m(content, filename, base_dir, subdir, overwrite, encoding)\u001b[39m\n\u001b[32m    160\u001b[39m path.parent.mkdir(parents=\u001b[38;5;28;01mTrue\u001b[39;00m, exist_ok=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    161\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m path.exists() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m overwrite:\n\u001b[32m--> \u001b[39m\u001b[32m162\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ArtifactError(\n\u001b[32m    163\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mArtifact already exists: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. Pass overwrite=True to replace.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    164\u001b[39m     )\n\u001b[32m    166\u001b[39m tmp = path.with_suffix(path.suffix + \u001b[33m\"\u001b[39m\u001b[33m.tmp\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    167\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[31mArtifactError\u001b[39m: Artifact already exists: C:\\Users\\labadmin\\AG-AISOFTDEV\\artifacts\\day1_user_stories.json. Pass overwrite=True to replace."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def validate_and_save_stories(stories_data):\n",
    "    \"\"\"Validates the structure of the user stories data and saves it if valid.\"\"\"\n",
    "    if not isinstance(stories_data, list) or not stories_data:\n",
    "        print(\"Validation Failed: Data is not a non-empty list.\")\n",
    "        return\n",
    "\n",
    "    required_keys = ['id', 'persona', 'user_story', 'acceptance_criteria']\n",
    "    all_stories_valid = True\n",
    "\n",
    "    # TODO: Implement the validation logic inside this function.\n",
    "    # 1. Loop through each story in the 'stories_data' list.\n",
    "    # 2. For each story, check if it contains all the 'required_keys'.\n",
    "    # 3. Also check if the 'acceptance_criteria' list is not empty.\n",
    "    # 4. If a story is invalid, print an error message and set 'all_stories_valid' to False.\n",
    "    #    (You can use 'continue' to skip to the next story).\n",
    "\n",
    "    for story in stories_data:\n",
    "        if not isinstance(story, dict):\n",
    "            print(f\"Validation Failed: Story is not a dictionary: {story}\")\n",
    "            all_stories_valid = False\n",
    "            continue\n",
    "        \n",
    "        missing_keys = [key for key in required_keys if key not in story]\n",
    "        if missing_keys:\n",
    "            print(f\"Validation Failed: Story is missing keys {missing_keys}: {story}\")\n",
    "            all_stories_valid = False\n",
    "            continue\n",
    "        \n",
    "        if not isinstance(story['acceptance_criteria'], list) or not story['acceptance_criteria']:\n",
    "            print(f\"Validation Failed: 'acceptance_criteria' is not a non-empty list in story: {story}\")\n",
    "            all_stories_valid = False\n",
    "            continue\n",
    "\n",
    "    if all_stories_valid:\n",
    "        print(\"\\nAll user stories passed validation.\")\n",
    "        artifact_path = \"artifacts/day1_user_stories.json\"\n",
    "        \n",
    "        # TODO: Call the save_artifact function from utils.py to save the data.\n",
    "        # Remember to convert the Python list back to a JSON string using json.dumps().\n",
    "        save_artifact(json.dumps(stories_data, indent=2), artifact_path)\n",
    "        print(f\"User stories saved to {artifact_path}\")\n",
    "    else:\n",
    "        print(\"\\nValidation failed. Artifact not saved.\")\n",
    "\n",
    "# Run the validation on the JSON data from the previous step\n",
    "if 'user_stories_json' in locals() and user_stories_json:\n",
    "    validate_and_save_stories(user_stories_json)\n",
    "else:\n",
    "    print(\"Skipping validation as user_stories_json is empty or not defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab Conclusion\n",
    "\n",
    "Congratulations! You have completed the first lab. You started with a vague, one-sentence problem and finished with a structured, validated, machine-readable requirements artifact. This is the critical first step in an AI-assisted software development lifecycle. The `day1_user_stories.json` file you created will be the direct input for our next lab, where we will generate a formal Product Requirements Document (PRD).\n",
    "\n",
    "> **Key Takeaway:** The single most important skill demonstrated in this lab is turning unstructured ideas into structured, machine-readable data (JSON). This transformation is what enables automation and integration with other tools later in the SDLC."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
